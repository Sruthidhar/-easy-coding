{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSNwtScjfcYEMrvDeBGtsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sruthidhar/-easy-coding/blob/main/CNN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),  # Explicitly define the input shape here\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "sGOUIOV1yJPM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow.keras.layers: Includes the building blocks for your neural network, such as Input, Conv2D, MaxPooling2D, Flatten, and Dense layers.\n",
        "\n",
        "tensorflow.keras.models.Sequential: Used to define a sequential model, where layers are stacked one after another in a linear pipeline.  \n",
        "\n",
        " inpu() initializes the model and tells it what shape of data to expect.\n",
        " Purpose: This layer extracts features like edges, textures, or patterns from the input image.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "32: Number of filters (or feature detectors). Each filter learns to detect a specific feature in the image.\n",
        "\n",
        "(3, 3): Size of each filter (3x3 pixels). A small filter size captures local details in the image.\n",
        "\n",
        "activation='relu': The ReLU activation function introduces non-linearity, enabling the model to learn complex patterns.\n",
        "\n",
        "This layer outputs a feature map, highlighting important areas in the image based on the filters."
      ],
      "metadata": {
        "id": "mnCaeIqE2frH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mnist: This is the MNIST dataset, a popular dataset of handwritten digit images (0‚Äì9) used for image classification tasks. It consists of 28x28 grayscale images.\n",
        "\n",
        "to_categorical: This function is used to convert numerical labels (e.g., 0, 1, 2, ..., 9) into one-hot encoded vectors, which are easier for the neural network to process in classification tasks.\n",
        "\n",
        "This function loads the MNIST dataset and splits it into:\n",
        "\n",
        "Training set (X_train, y_train): Used to train the model.\n",
        "\n",
        "Validation set (X_val, y_val): Used to validate the model's performance on unseen data.\n",
        "\n",
        "The dataset returns:\n",
        "\n",
        "X_train and X_val: Contain the images as NumPy arrays, each with dimensions (28, 28).\n",
        "\n",
        "y_train and y_val: Contain the corresponding digit labels (e.g., 0, 1, 2,..., 9).\n",
        "\n",
        "Reshaping:\n",
        "\n",
        "X_train.reshape((-1, 28, 28, 1)): Reshapes each image from (28, 28) to (28, 28, 1).\n",
        "\n",
        "28, 28: Image height and width.\n",
        "\n",
        "1: Number of channels (grayscale images have 1 channel, while RGB images would have 3).\n",
        "\n",
        "-1: Automatically calculates the number of samples (ensures the data dimensions align correctly).\n",
        "\n",
        "The new shape is required because Convolutional Neural Networks (CNNs) expect a 4D input: (samples, height, width, channels).\n",
        "\n",
        "Normalization:\n",
        "\n",
        "/ 255.0: Scales the pixel values from the range [0, 255] to [0, 1].\n",
        "\n",
        "Why? Neural networks perform better when inputs are scaled to a smaller range, as it stabilizes and speeds up training."
      ],
      "metadata": {
        "id": "9NTYp6887EhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape((-1, 28, 28, 1)) / 255.0  # Normalize and reshape\n",
        "X_val = X_val.reshape((-1, 28, 28, 1)) / 255.0\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode labels\n",
        "y_val = to_categorical(y_val, num_classes=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU9nIZ_IyMuK",
        "outputId": "d5f94f5a-1621-42a4-acf3-ef5fb84cfc3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "85kr4tPU7j1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Required Libraries\n",
        "Sequential and Layers: Used to build the neural network with stacked layers.\n",
        "\n",
        "mnist: The dataset consisting of 28x28 grayscale images of digits (0-9).\n",
        "\n",
        "to_categorical: Converts numerical labels into a one-hot encoded format, suitable for multi-class classification.\n",
        "\n",
        "2. Load and Preprocess the Data\n",
        "mnist.load_data(): Loads the MNIST dataset, splitting it into training and validation sets.\n",
        "\n",
        "X_train, y_train: Training data (images and labels).\n",
        "\n",
        "X_val, y_val: Validation data.\n",
        "\n",
        "Reshaping & Normalizing:\n",
        "\n",
        "Images are reshaped to include a channel dimension (e.g., (28, 28, 1) for grayscale).\n",
        "\n",
        "3. Define the CNN Model\n",
        "The CNN is built using a Sequential model with the following layers:\n",
        "\n",
        "Input Layer (Input): Specifies the shape of the input data (28, 28, 1).\n",
        "\n",
        "Convolutional Layer (Conv2D): Applies 32 filters with a kernel size of (3, 3) to extract features from the images. Activation function: ReLU.\n",
        "\n",
        "Max Pooling Layer (MaxPooling2D): Down-samples feature maps by taking the maximum value in a (2, 2) window, reducing spatial dimensions.\n",
        "\n",
        "Flatten Layer (Flatten): Flattens the 2D feature maps into a 1D vector for the dense layers.\n",
        "\n",
        "Dense Layer (Hidden): Contains 128 neurons with ReLU activation for complex pattern recognition.\n",
        "\n",
        "Dense Layer (Output): Contains 10 neurons with a softmax activation to predict the probability of each digit (0-9).\n",
        "\n",
        "4. Compile the Model\n",
        "Optimizer (adam): Adaptive optimization algorithm for efficient training.\n",
        "\n",
        "Loss Function (categorical_crossentropy): Computes the error for multi-class classification tasks.\n",
        "\n",
        "Metric (accuracy): Tracks the accuracy of the model during training.\n",
        "\n",
        "5. Train the Model\n",
        "Training (fit): The model learns by:\n",
        "\n",
        "Training on X_train and y_train.\n",
        "\n",
        "Validating on X_val and y_val to monitor performance.\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "epochs=10: Number of passes through the entire dataset.\n",
        "\n",
        "batch_size=32: Number of samples per training step.\n",
        "\n",
        "This model will attempt to classify each image into one of 10 digits by learning patterns from the training set and testing its performance on the validation set. It's a simple but powerful example of CNNs in action! Let me know if you'd like deeper insights into any part of this process! üöÄ"
      ],
      "metadata": {
        "id": "zAFvmoq18NB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()\n",
        "X_train = X_train.reshape((-1, 28, 28, 1)) / 255.0\n",
        "X_val = X_val.reshape((-1, 28, 28, 1)) / 255.0\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_val = to_categorical(y_val, num_classes=10)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "VtrjpIzMyVyl",
        "outputId": "d899ec5a-7501-42d6-c1de-ff27b316e869"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17ms/step - accuracy: 0.9147 - loss: 0.2900 - val_accuracy: 0.9771 - val_loss: 0.0694\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.9839 - loss: 0.0535 - val_accuracy: 0.9856 - val_loss: 0.0467\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.9903 - loss: 0.0322 - val_accuracy: 0.9854 - val_loss: 0.0440\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fbb0eac0957a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}